{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import quote # this is used to fix illegal characters in the titlenames.\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resaved the metacritic_movies.csv to get rid of commas in the numbers.\n",
    "# Created schema for movies_t. Imported data into table just to make sure it worked, then deleted the table, and recreated\n",
    "# to be an empty table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>meta_mixed</th>\n",
       "      <th>meta_negative</th>\n",
       "      <th>meta_positive</th>\n",
       "      <th>metascore</th>\n",
       "      <th>user_mixed</th>\n",
       "      <th>user_negative</th>\n",
       "      <th>user_positive</th>\n",
       "      <th>userscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Anatomy of a Murder</td>\n",
       "      <td>1-Jul-59</td>\n",
       "      <td>Drama,Mystery,Thriller,Crime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bringing Up Baby</td>\n",
       "      <td>18-Feb-38</td>\n",
       "      <td>Comedy,Romance,Family</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>After Life</td>\n",
       "      <td>12-May-99</td>\n",
       "      <td>Drama,Fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Gavagai</td>\n",
       "      <td>3-Aug-18</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Hustler</td>\n",
       "      <td>25-Sep-61</td>\n",
       "      <td>Drama,Sport</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>tbd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_title release_date                         genre  meta_mixed  \\\n",
       "0  Anatomy of a Murder     1-Jul-59  Drama,Mystery,Thriller,Crime           0   \n",
       "1     Bringing Up Baby    18-Feb-38         Comedy,Romance,Family           0   \n",
       "2           After Life    12-May-99                 Drama,Fantasy           0   \n",
       "3              Gavagai     3-Aug-18                         Drama           1   \n",
       "4          The Hustler    25-Sep-61                   Drama,Sport           1   \n",
       "\n",
       "   meta_negative  meta_positive  metascore user_mixed user_negative  \\\n",
       "0              0             15         95          0             0   \n",
       "1              1             16         91          1             0   \n",
       "2              0             19         91          0             2   \n",
       "3              0              6         91          0             1   \n",
       "4              0             17         90          0             0   \n",
       "\n",
       "  user_positive userscore  \n",
       "0             3       tbd  \n",
       "1             2       tbd  \n",
       "2             1       tbd  \n",
       "3             2       tbd  \n",
       "4             3       tbd  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the movies data.\n",
    "csv_file = \"Metacritic Reviews/metacritic_movies.csv\"\n",
    "raw_movies_df = pd.read_csv(csv_file)\n",
    "raw_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews data cleaning\n",
    "# Previewed in Excel.\n",
    "# Removed lines of invalid data that appears to have wrapped incorrectly.\n",
    "\n",
    "# Need to fix text for the apostrophes that have been convered to â€™\n",
    "# Did Find/Replace using text editor.\n",
    "# \n",
    "# created file Cleaned_metacritic_reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_name</th>\n",
       "      <th>media</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>individual_meta_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Robbie Collin</td>\n",
       "      <td>The Telegraph</td>\n",
       "      <td>Jojo Rabbit</td>\n",
       "      <td>7-Oct-19</td>\n",
       "      <td>20</td>\n",
       "      <td>As satire it's a dismal dereliction of duty; a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Roger Moore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrie Pilby</td>\n",
       "      <td>7-Oct-19</td>\n",
       "      <td>38</td>\n",
       "      <td>Carrie Pilby never rises to the level of hatef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Empire</td>\n",
       "      <td>Gemini Man</td>\n",
       "      <td>7-Oct-19</td>\n",
       "      <td>40</td>\n",
       "      <td>It gives you two Will Smiths for the price of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Noel Murray</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>In the Tall Grass</td>\n",
       "      <td>7-Oct-19</td>\n",
       "      <td>50</td>\n",
       "      <td>Despite the handsome Craig Wrobleski cinematog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jesse Hassenger</td>\n",
       "      <td>The A.V. Club</td>\n",
       "      <td>The King</td>\n",
       "      <td>7-Oct-19</td>\n",
       "      <td>50</td>\n",
       "      <td>It's hard to feel energized by a historical ep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       critic_name              media        movie_title review_date  \\\n",
       "0    Robbie Collin      The Telegraph        Jojo Rabbit    7-Oct-19   \n",
       "1      Roger Moore                NaN       Carrie Pilby    7-Oct-19   \n",
       "2              NaN             Empire         Gemini Man    7-Oct-19   \n",
       "3      Noel Murray  Los Angeles Times  In the Tall Grass    7-Oct-19   \n",
       "4  Jesse Hassenger      The A.V. Club           The King    7-Oct-19   \n",
       "\n",
       "  individual_meta_score                                               text  \n",
       "0                    20  As satire it's a dismal dereliction of duty; a...  \n",
       "1                    38  Carrie Pilby never rises to the level of hatef...  \n",
       "2                    40  It gives you two Will Smiths for the price of ...  \n",
       "3                    50  Despite the handsome Craig Wrobleski cinematog...  \n",
       "4                    50  It's hard to feel energized by a historical ep...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the reviews data.\n",
    "csv_file = \"Metacritic Reviews/Cleaned_metacritic_reviews.csv\"\n",
    "raw_reviews_df = pd.read_csv(csv_file, dtype={3:'str',4:'str'})\n",
    "raw_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addy's section\n",
    "\n",
    "# Need to create table of movie posters urls from TheMovieDB.org\n",
    "#\n",
    "# Choice 1: Lookup table\n",
    "#    Movie name, poster url\n",
    "\n",
    "# Choice 2: Append a new column for poster url to movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://api.themoviedb.org/3/movie/550?api_key=3d48b9204ca053957eb4375bb97a83c8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep\n",
    "config_path = 'http://api.themoviedb.org/3/configuration?api_key={key}'\n",
    "KEY = '3d48b9204ca053957eb4375bb97a83c8'\n",
    "url = config_path.format(key=KEY)\n",
    "r = requests.get(url)\n",
    "config = r.json()\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://image.tmdb.org/t/p/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep\n",
    "base_url = config['images']['base_url']\n",
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "# This is what happens if there's no poster.\n",
    "\n",
    "temp = 'http://api.themoviedb.org/3/search/movie?query=\"Besotted\"&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "r = requests.get(temp)\n",
    "response = r.json()\n",
    "if response['results'][0]['poster_path'] is None:\n",
    "    print('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what happens if the movie title is not found.\n",
    "\n",
    "temp = 'http://api.themoviedb.org/3/search/movie?query=\"dasgdsf\"&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "r = requests.get(temp)\n",
    "response = r.json()\n",
    "response['total_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 7,\n",
       " 'status_message': 'Invalid API key: You must be granted a valid key.',\n",
       " 'success': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what happens if the movie title has # in it.\n",
    "\n",
    "temp = 'http://api.themoviedb.org/3/search/movie?query=\"#Horror\"&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "r = requests.get(temp)\n",
    "response = r.json()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.themoviedb.org/3/search/movie?query=%23Horror&api_key=3d48b9204ca053957eb4375bb97a83c8\n"
     ]
    }
   ],
   "source": [
    "# This is what happens if the movie title has # in it.\n",
    "\n",
    "movieTitle=quote('#Horror')\n",
    "temp = 'http://api.themoviedb.org/3/search/movie?query=' + movieTitle + '&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "print(temp)\n",
    "#r = requests.get(temp)\n",
    "#response = r.json()\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/eUL2USo8weZHhNMJuWwKtegJzhL.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure why this movie is one that has the values in the tuple swapped.\n",
    "\n",
    "movieTitle=quote('No Home Movie')\n",
    "temp = 'http://api.themoviedb.org/3/search/movie?query=' + movieTitle + '&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "#print(temp)\n",
    "r = requests.get(temp)\n",
    "response = r.json()\n",
    "response['results'][0]['poster_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reused\n",
    "# base_url = 'http://image.tmdb.org/t/p/'\n",
    "# size = 'w500'\n",
    "# rel_path = '/mgwZvl0DwS1GIborSGlpTGomrJD.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://image.tmdb.org/t/p/'\n",
    "size = 'w500' # We're looking for 500px sized posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Begin Data Retreival. Rows left.\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................9100.........................9075.........................9050.........................9025.........................9000.........................8975.........................8950.........................8925.........................8900.........................8875.........................8850.........................8825.........................8800.........................8775.........................8750.........................8725.........................8700.........................8675.........................8650.........................8625.........................8600.........................8575.........................8550.........................8525.........................8500.........................8475.........................8450.........................8425.........................8400.........................8375.........................8350.........................8325.........................8300.........................8275.........................8250.........................8225.........................8200.........................8175.........................8150.........................8125.........................8100.........................8075.........................8050.........................8025.........................8000.........................7975.........................7950.........................7925.........................7900.........................7875.........................7850.........................7825.........................7800.........................7775.........................7750.........................7725.........................7700.........................7675.........................7650.........................7625.........................7600.........................7575.........................7550.........................7525.........................7500.........................7475.........................7450.........................7425.........................7400.........................7375.........................7350.........................7325.........................7300.........................7275.........................7250.........................7225.........................7200.........................7175.........................7150.........................7125.........................7100.........................7075.........................7050.........................7025.........................7000.........................6975.........................6950.........................6925.........................6900.........................6875.........................6850.........................6825.........................6800.........................6775.........................6750.........................6725.........................6700.........................6675.........................6650.........................6625.........................6600.........................6575.........................6550.........................6525.........................6500.........................6475.........................6450.........................6425.........................6400.........................6375.........................6350.........................6325.........................6300.........................6275.........................6250.........................6225.........................6200.........................6175.........................6150.........................6125.........................6100.........................6075.........................6050.........................6025.........................6000.........................5975.........................5950.........................5925.........................5900.........................5875.........................5850.........................5825.........................5800.........................5775.........................5750.........................5725.........................5700.........................5675.........................5650.........................5625.........................5600.........................5575.........................5550.........................5525.........................5500.........................5475.........................5450.........................5425.........................5400.........................5375.........................5350.........................5325.........................5300.........................5275.........................5250.........................5225.........................5200.........................5175.........................5150.........................5125.........................5100.........................5075.........................5050.........................5025.........................5000.........................4975.........................4950.........................4925.........................4900.........................4875.........................4850.........................4825.........................4800.........................4775.........................4750.........................4725.........................4700.........................4675.........................4650.........................4625.........................4600.........................4575.........................4550.........................4525.........................4500.........................4475.........................4450.........................4425.........................4400.........................4375.........................4350.........................4325.........................4300.........................4275.........................4250.........................4225.........................4200.........................4175.........................4150.........................4125.........................4100.........................4075.........................4050.........................4025.........................4000.........................3975.........................3950.........................3925.........................3900.........................3875.........................3850.........................3825.........................3800.........................3775.........................3750.........................3725.........................3700.........................3675.........................3650.........................3625.........................3600.........................3575.........................3550.........................3525.........................3500.........................3475.........................3450.........................3425.........................3400.........................3375.........................3350.........................3325.........................3300.........................3275.........................3250.........................3225.........................3200.........................3175.........................3150.........................3125.........................3100.........................3075.........................3050.........................3025.........................3000.........................2975.........................2950.........................2925.........................2900.........................2875.........................2850.........................2825.........................2800.........................2775.........................2750.........................2725.........................2700.........................2675.........................2650.........................2625.........................2600.........................2575.........................2550.........................2525.........................2500.........................2475.........................2450.........................2425.........................2400.........................2375.........................2350.........................2325.........................2300.........................2275.........................2250.........................2225.........................2200.........................2175.........................2150.........................2125.........................2100.........................2075...................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....2050.........................2025.........................2000.........................1975.........................1950.........................1925.........................1900.........................1875.........................1850.........................1825.........................1800.........................1775.........................1750.........................1725.........................1700.........................1675.........................1650.........................1625.........................1600.........................1575.........................1550.........................1525.........................1500.........................1475.........................1450.........................1425.........................1400.........................1375.........................1350.........................1325.........................1300.........................1275.........................1250.........................1225.........................1200.........................1175.........................1150.........................1125.........................1100.........................1075.........................1050.........................1025.........................1000.........................975.........................950.........................925.........................900.........................875.........................850.........................825.........................800.........................775.........................750.........................725.........................700.........................675.........................650.........................625.........................600.........................575.........................550.........................525.........................500.........................475.........................450.........................425.........................400.........................375.........................350.........................325.........................300.........................275.........................250.........................225.........................200.........................175.........................150.........................125.........................100.........................75.........................50.........................25.........................0.\n",
      "\n",
      "-----------------------------\n",
      "Data Retrieval Complete\n",
      "-----------------------------\n",
      "Movies not found: 62\n",
      "Movies with no posters: 316\n",
      "Other errors: 0\n",
      "\n",
      "See the files movies_not_found.txt, posters_not_found.txt, and keyerrors.txt for details.\n"
     ]
    }
   ],
   "source": [
    "url_list = []\n",
    "\n",
    "# the following 2 lists aren't needed since we're just writing them to a file.\n",
    "#movie_not_found_list = []\n",
    "#poster_not_found_list = []\n",
    "\n",
    "processed_count = len(raw_movies_df)\n",
    "movies_not_found_count = 0\n",
    "posters_not_found_count = 0\n",
    "keyerrors_count = 0\n",
    "\n",
    "keyerrors_f = open(\"keyerrors.txt\", \"w\")\n",
    "movies_not_found_f = open(\"movies_not_found.txt\", \"w\")\n",
    "posters_not_found_f = open(\"posters_not_found.txt\", \"w\")\n",
    "url_list_f = open(\"url_list.txt\", \"w\")\n",
    "\n",
    "print('-----------------------------')\n",
    "print('Begin Data Retreival. Rows left.')\n",
    "print('-----------------------------\\n')\n",
    "for title in raw_movies_df.movie_title:\n",
    "    #print(title)\n",
    "    temp = 'http://api.themoviedb.org/3/search/movie?query=' + quote(title) + '&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "    #print(temp)\n",
    "    try:\n",
    "        r = requests.get(temp)\n",
    "        response = r.json()\n",
    "        \n",
    "        if (response['total_results'] != 0) and (response['results'][0]['poster_path'] is not None):\n",
    "            url = base_url + size + response['results'][0]['poster_path']\n",
    "            url_list.append({title, url})\n",
    "            url_list_f.write(title + \"\\t\" + url + \"\\n\") # make it Tab delimited instead.\n",
    "        elif response['total_results'] == 0:\n",
    "            #error_list.append(f'{title} not found. Skipping...')\n",
    "            #movie_not_found_list.append(title)\n",
    "            movies_not_found_f.write(title + '\\n')\n",
    "            movies_not_found_count += 1\n",
    "        elif response['results'][0]['poster_path'] is None:\n",
    "            #print(f'No poster found for {title}.')\n",
    "            #poster_not_found_list.append(title)\n",
    "            posters_not_found_f.write(title + '\\n')\n",
    "            posters_not_found_count += 1\n",
    "        \n",
    "        # Commmented out as this was printing out the complete list each time... \n",
    "        # print(url_list)\n",
    "        \n",
    "        #read json into a list\n",
    "        #movie_url.append(response_json, [url])\n",
    "        \n",
    "        #Print a period every iteration so that we know this is still running\n",
    "        processed_count -= 1\n",
    "        if (processed_count % 25 == 0):\n",
    "            print(processed_count, end = '') # print the number left on every count divisable by 25.\n",
    "        print('.', end = '')\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f'\\n ** keyerror with {title} ** \\n')\n",
    "        keyerrors_count += 1\n",
    "        keyerrors_f.write(title + '\\n')\n",
    "    \n",
    "# close the files.\n",
    "url_list_f.close()\n",
    "keyerrors_f.close()\n",
    "movies_not_found_f.close()\n",
    "posters_not_found_f.close()\n",
    "\n",
    "print('\\n\\n-----------------------------')\n",
    "print('Data Retrieval Complete')\n",
    "print('-----------------------------')\n",
    "print(f'Movies not found: {movies_not_found_count}')\n",
    "print(f'Movies with no posters: {posters_not_found_count}')\n",
    "print(f'Other errors: {keyerrors_count}\\n')\n",
    "print('See the files movies_not_found.txt, posters_not_found.txt, and keyerrors.txt for details.')      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8738</td>\n",
       "      <td>http://image.tmdb.org/t/p/w500/vIb9kzseUun3QGo...</td>\n",
       "      <td>Wild Reeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8739</td>\n",
       "      <td>No Home Movie</td>\n",
       "      <td>http://image.tmdb.org/t/p/w500/eUL2USo8weZHhNM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8740</td>\n",
       "      <td>http://image.tmdb.org/t/p/w500/yRMex0csH3oI05Y...</td>\n",
       "      <td>Solas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8741</td>\n",
       "      <td>http://image.tmdb.org/t/p/w500/43ffZhMCWQhzMne...</td>\n",
       "      <td>J.T. Leroy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8742</td>\n",
       "      <td>http://image.tmdb.org/t/p/w500/jcuEDKnM3uThdz7...</td>\n",
       "      <td>Donnybrook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_title  \\\n",
       "8738  http://image.tmdb.org/t/p/w500/vIb9kzseUun3QGo...   \n",
       "8739                                      No Home Movie   \n",
       "8740  http://image.tmdb.org/t/p/w500/yRMex0csH3oI05Y...   \n",
       "8741  http://image.tmdb.org/t/p/w500/43ffZhMCWQhzMne...   \n",
       "8742  http://image.tmdb.org/t/p/w500/jcuEDKnM3uThdz7...   \n",
       "\n",
       "                                             poster_url  \n",
       "8738                                         Wild Reeds  \n",
       "8739  http://image.tmdb.org/t/p/w500/eUL2USo8weZHhNM...  \n",
       "8740                                              Solas  \n",
       "8741                                         J.T. Leroy  \n",
       "8742                                         Donnybrook  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df = pd.DataFrame(url_list, columns = ['movie_title','poster_url'])\n",
    "url_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No clue why the title and url would get swapped like that!! :-/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we still need to do this?\n",
    "\n",
    "# result = pd.concat([movie_title_df, url_df],axis= , sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference\n",
    "# for title in raw_movies_df.movie_title:\n",
    "#     #print(title)\n",
    "#     temp = 'http://api.themoviedb.org/3/search/movie?query=\"' + title + '\"&api_key=3d48b9204ca053957eb4375bb97a83c8'\n",
    "#     #print(temp)\n",
    "#     r = requests.get(temp)\n",
    "#     response = r.json()\n",
    "#     url = base_url + size + response['results'][0]['poster_path']\n",
    "#     print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if we can pull up a movie poster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
